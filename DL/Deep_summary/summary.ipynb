{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fancy-theorem",
   "metadata": {},
   "source": [
    "## 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-population",
   "metadata": {},
   "source": [
    "퍼셉트론은 다수의 입력신호를 하나의 출력신호로 변환해주는 알고리즘을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-money",
   "metadata": {},
   "source": [
    "### 퍼셉트론 식\n",
    "퍼셉트론의 기본단위는 유닛이고, 퍼셉트론의 식은 가중치와 입력값을 내적한 결과에 편향을 더한 뒤 활성화 함수를 취한 형태입니다.\n",
    "$$ y_i = \\sigma(w_1x_1 + w_2x_2 .... + b) $$\n",
    "- $y_i$ 출력값 : 퍼셉트론의 결과값 입니다.\n",
    "- $x_i$ 입력값 : 벡터 형태의 입력변수들의 집합입니다.\n",
    "- $w_i$ 가중치 : 입력값의 원소중 중요하다고 여겨지는 원소에 가중치는 주는 매개변수 벡터로 Hebb's rule에 의하여 두 유닛이 동시에 활성화될 때마다 이들 사이의 연결 가중치 값이 증가하게 됩니다.\n",
    "- $b$ 편향 : 가중치와 같은 매개변수 벡터로 유닛의 활성화 경계선을 결정하는 역할을 합니다.\n",
    "- $\\sigma$ 활성화 함수 : 유닛의 활성화 여부를 결정하는 비선형 함수로 내적된 값에 비선형성을 추가해줍니다. 비선형성을 추가함으로써, 층을 쌓는 다층 퍼셉트론을 만들 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-jersey",
   "metadata": {},
   "source": [
    "## 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-dispatch",
   "metadata": {},
   "source": [
    "퍼셉트론에 층을 쌓음으로써 복잡한 패턴을 가진 데이터도 예측, 분류가 가능해진 형태로 다층 신경망이라고 부릅니다. 다층 신경망의 일반적인 구조는 입력층, 은닉층, 출력층으로 나뉘어져 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-tours",
   "metadata": {},
   "source": [
    "### 순전파"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-transport",
   "metadata": {},
   "source": [
    "순전파는 입력값에 내적과 활성화 함수를 반복적으로 적용하여 입력값의 주요 특성을 찾아가는 과정을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-lafayette",
   "metadata": {},
   "source": [
    "### 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-tender",
   "metadata": {},
   "source": [
    "역전파는 가중치 변화율에 따른 손실함수 변화율을 통하여 손실함수가 최소가 되도록 가중치를 갱신하는 과정을 말합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-abortion",
   "metadata": {},
   "source": [
    "### 신경망이 해결가능한 문제\n",
    "1. 회귀 예측\n",
    "- 출력층의 활성화 함수로는 주로 렐루와 소프트플러스 활성화 함수를 사용합니다.\n",
    "- 예측값과 실제값 사이의 차이를 활용한 손실함수를 이용하여 손실함수가 가장 작은 순간의 가중치를 최적화 기법을 이용하여 찾습니다.  \n",
    "- 손실함수로 사용되는 지표 ex) 평균제곱오차\n",
    "2. 분류 예측\n",
    "- 이진 분류 문제의 경우 마지막 출력층에 활성화 함수로 시그모이드 함수를 사용하여 0~1 사이의 값으로 출력하고 임계값을 찾습니다.\n",
    "- 다중 분류 문제의 경우 활성화 함수로 소프트맥스 함수를 사용합니다.\n",
    "- 잘 분류가 되었는지 알기 위한 정량적 지표로 교차 엔트로피를 손실함수로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-symposium",
   "metadata": {},
   "source": [
    "## 신경망 훈련 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-patient",
   "metadata": {},
   "source": [
    "일반적으로 신경망, 즉 모델의 만드는데 모델의 성능을 조금이라도 더 높이고 모델의 성능을 객관적으로 평가하기 위하여 전체 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나누어서 모델을 구축합니다.\n",
    "- 훈련 데이터 : 모델을 실질적으로 만드는데 사용되는 데이터입니다.\n",
    "- 검증 데이터 : 훈련 데이터에 포함되지 않고, 훈련 데이터로 만들어진 모델을 검증하기 위한 데이터로, 적절한 모델의 선택 및 모델의 하이퍼파라미터 튜닝을 하는데 사용되는 데이터입니다.\n",
    "- 테스트 데이터 : 최종적으로 모델의 검증과 튜닝이 끝나고 모델이 예측해야 하는 실물 데이터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-correspondence",
   "metadata": {},
   "source": [
    "### 배치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-science",
   "metadata": {},
   "source": [
    "**모델에 한번에 들어가는 훈련 데이터의 개수를 배치**라고 부릅니다. 하지만 훈련 데이터의 개수가 너무 많은 경우 전체 훈련 데이터를 N등분하여 나누어서 훈련을 시키는데 여기서 **N등분 되어진 일부 훈련 데이터를 미니배치**라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-tourism",
   "metadata": {},
   "source": [
    "### 에폭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-humanity",
   "metadata": {},
   "source": [
    "전체 훈련 데이터가 모델에 적어도 한번씩 들어가면 해당 모델은 1에폭을 순환했다고 봅니다. 만약 총 100개의 훈련 데이터가 20개의 미니배치로 나누어져서 모델에 들어가 학습될 때, 100개의 훈련 데이터가 모두 학습이 되어졌으면 1에폭을 순환했다고 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-arthur",
   "metadata": {},
   "source": [
    "### 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-sleeve",
   "metadata": {},
   "source": [
    "모델이 훈련 데이터에서는 성능이 굉장히 좋았지만, 훈련 데이터에 과하게 적합되어져서 검증 데이터나 테스트 데이터에서는 성능이 굉장히 떨어지는 현상을 말합니다.  \n",
    "모델의 복잡성이 높고 새로운 데이터를 예측할 만한 모델 유연성을 없다는 의미입니다.  \n",
    "모델이 예측한 값의 분산은 굉장히 크고 편향은 낮을 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-testimony",
   "metadata": {},
   "source": [
    "### 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-damage",
   "metadata": {},
   "source": [
    "과소적합은 모델이 어떠한 데이터에서든지 성능이 좋지 못한 현상을 말합니다.  \n",
    "모델의 복잡성은 낮지만 모델의 유연성이 너무 높아서 제대로된 예측을 하지 못하는 모델이 완성되어집니다.  \n",
    "모델이 예측한 값의 분산은 낮지만 편향은 클 것 입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
