{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executed-cooperative",
   "metadata": {},
   "source": [
    "## Sequntial API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-issue",
   "metadata": {},
   "source": [
    "사용할 패키지를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sufficient-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import standard_scaling, R_squared, train_val_split\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-merit",
   "metadata": {},
   "source": [
    "캘리포니아 집값 데이터 클래스를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chronic-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-ceramic",
   "metadata": {},
   "source": [
    "데이터를 훈련, 검증, 테스트 데이터로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marked-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-student",
   "metadata": {},
   "source": [
    "입력값들을 정규화 시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exclusive-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = standard_scaling(x_train)\n",
    "x_val = standard_scaling(x_val)\n",
    "x_test = standard_scaling(x_test)\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_val = y_val.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-charter",
   "metadata": {},
   "source": [
    "Sequential api로 keras모델을 만들되 하이퍼파라미터를 조절가능한 형태의 모델로 만들기 위해 모델을 만드는 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nearby-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        n_hidden: 은닉층의 개수 (하이퍼파라미터)\n",
    "        n_neurons: 각 은닉층의 유닛 갯수 (하이퍼파라미터)\n",
    "        learning_rate: 최적화 기법의 학습률 (하이퍼파라미터)\n",
    "        input_shape: 모델에 들어가는 입력변수의 개수\n",
    "    return:\n",
    "        keras model\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-suicide",
   "metadata": {},
   "source": [
    "kears model을 회귀모델로 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceramic-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "# # 학습 시작\n",
    "# keras_reg.fit(x_train, \n",
    "#               y_train,\n",
    "#               epochs=100,\n",
    "#               validation_data=(x_val, y_val),\n",
    "#               callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    "#               )\n",
    "# # 점수 출력\n",
    "# mse_test = keras_reg.score(x_test, y_test)\n",
    "# y_pred = keras_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-johnson",
   "metadata": {},
   "source": [
    "하이퍼파라미터 조정을 위한 sklearn의 RandomizedSearchCV 적용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cardiovascular-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 3ms/step - loss: 1.1100 - val_loss: 0.9071\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.6096\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 1.0599 - val_loss: 0.6856\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.6817\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 1.0023 - val_loss: 0.6893\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.5810\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.8701 - val_loss: 0.5317\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 0.6117\n",
      "179/182 [============================>.] - ETA: 0s - loss: 3.8599WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 3.8227 - val_loss: 15.3798\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 1.5344\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 1.3179 - val_loss: 0.8295\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 1.7190\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7675 - val_loss: 0.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000157C70A4FD0>,\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'learning_rate': [0.01],\n",
       "                                        'n_hidden': (0, 1, 2, 3),\n",
       "                                        'n_neurons': [20, 21, 22, 23, 24, 25,\n",
       "                                                      26, 27, 28, 29, 30, 31,\n",
       "                                                      32, 33, 34, 35, 36, 37,\n",
       "                                                      38, 39, 40, 41, 42, 43,\n",
       "                                                      44, 45, 46, 47, 48, 49]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\":(0,1,2,3), # 은닉층 개수\n",
    "    \"n_neurons\": np.arange(20,50).tolist(), # 은닉층의 유닛 개수\n",
    "    \"learning_rate\": np.arange(0.01,0.02).tolist() # 학습률\n",
    "}\n",
    "# 랜덤서치cv 기법을 10의 에폭과 cross validation은 3등분 합니다.\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=3, cv=2)\n",
    "# 각 하이퍼파라미터를 적용한 모델 학습을 시작합니다.\n",
    "rnd_search_cv.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-small",
   "metadata": {},
   "source": [
    "최적의 하이퍼파라미터를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "anticipated-nerve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 38, 'n_hidden': 3, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-bread",
   "metadata": {},
   "source": [
    "다양한 조건의 모델중에서 가장 성능이 좋은 모델의 점수를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "explicit-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5963866412639618"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-greek",
   "metadata": {},
   "source": [
    "최적의 파라미터를 가진 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mobile-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-phenomenon",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터\n",
    "- 은닉층의 개수\n",
    "- 은닉층의 유닛 개수\n",
    "- 학습률\n",
    "- 배치 크기\n",
    "- 옵티마이저\n",
    "- 활성화 함수\n",
    "- 반복 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-bruce",
   "metadata": {},
   "source": [
    "#### 은닉층의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-signature",
   "metadata": {},
   "source": [
    "- 은닉층의 갯수가 많아질수록 깊은 네트워크를 가진 심층 신경망이라고 부릅니다. 복잡한 문제를 해결하는데는 얕은 신경망 보다는 심층 신경망이 파라미터 효율성이 좋고 동일한 양의 훈련 데이터에서 더 높은 성능을 부릅니다.  \n",
    "- 은닉층은 입력층과 가까울수록 단순한 패턴을 모델링하고 출력층과 가까울수록 복잡한 패턴을 모델링합니다.\n",
    "- 단순한 패턴이 잘 학습된 모델을 일부 복잡한 패턴을 따로 학습시키는 전이학습 방법을 사용하여 다양한 문제를 해결하기 위한 기본 토대가 되어질 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-testament",
   "metadata": {},
   "source": [
    "#### 은닉층의 유닛개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-documentation",
   "metadata": {},
   "source": [
    "- 은닉층의 일반적인 유닛개수 구성방식은 각층의 뉴런을 점점 줄여서 깔때기 처럼 구성합니다. 이로인하여 저수준의 많은 특성이 고수준의 적은 특성으로 합쳐질 수 있기 떄문입니다.\n",
    "- 하지만 최근에는 모든 층의 유닛개수를 동일하게 하거나 점점 더 많아지는 방식으로도 성능개선을 보입니다.\n",
    "- 처음 첫번째 은닉층의 유닛개수는 여유있게 두는 것이 좋습니다.\n",
    "- 실전에서는 많은 수의 은닉층과 유닛개수를 사용하고 조기종료나 규제기법을 사용하여 찾아가는 방식의 스트레치 팬츠(stretch pants)방식이 자주 사용되어 집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-draft",
   "metadata": {},
   "source": [
    "#### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-brand",
   "metadata": {},
   "source": [
    "- 매우 낮은 학습률에서 시작하여 점진적으로 매우 큰 학습률까지 반복적으로 모델을 훈련하는 방법이 있습니다.\n",
    "- 최적의 학습률은 손실이 다시 상승하는 지점보다 조금 아래에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-spectrum",
   "metadata": {},
   "source": [
    "#### 배치 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-berlin",
   "metadata": {},
   "source": [
    "- 큰 배치 크기를 사용하면 GPU와 같은 하드웨어 가속기를 효율적으로 활용이 가능합니다.\n",
    "- 배치 크기가 커지면 한번에 처리할 데이터 수가 증가하므로 초당 더 많은 데이터를 처리할 수 있습니다.\n",
    "- Yan Lecun 2~32개의 배치크기가 좋다\n",
    "- 학습률 예열을 사용하여 큰 배치 크기를 시도하기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-latitude",
   "metadata": {},
   "source": [
    "#### ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-jefferson",
   "metadata": {},
   "source": [
    "Leslie Smith의 2018년 논문에 신경망 하이퍼파라미터 튜닝에 관한 좋은 모범 사례가 소개되어 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
