{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망에서 말하는 학습이란, 훈련 데이터로부터 정답값과 예측값 사이를 최대한 가깝도록 만드는 최적의 매개변수를 획득하는 과정을 말합니다.\n",
    "신경망에서 학습의 의미\n",
    "Yes / No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습에서 데이터가 가지는 의미에 대한 내용으로 올바르지 않은 것을 고르시오.\n",
    "데이터의 의미\n",
    "1. 기계학습은 데이터를 통하여 답을 찾고, 패턴을 학습합니다.\n",
    "2. 인간은 경험을 통하여 패턴을 찾고 기계학습은 데이터를 통하여 패턴을 찾습니다.\n",
    "3. 기계학습은 데이터에서 특징을 추출하고 그 특징에서 패턴을 찾아 학습합니다.\n",
    "4. 고전적인 기계학습에서는 인간이 개입하여 특징을 만드는 반면 딥러닝에서는 인간의 개입 없이 특징을 만들어냅니다.\n",
    "5. 기계학습에서 데이터의 전처리부분은 전적으로 컴퓨터가 처리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 5번 데이터의 전처리 부분에서 사람이 개입하여야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 학습에 대한 내용으로 올바르지 않은 것을 고르시오.\n",
    "신경망의 학습\n",
    "1. 신경망에서는 이미지의 특징을 SIFT, SURF등의 알고리즘을 통해서 사람이 설계했지만, 기계학습은 이미지에 포함된 중요한 특징까지 스스로 학습합니다.\n",
    "2. 딥러닝을 종단간 기계학습(end-to-end machine learning)이라고 부릅니다.\n",
    "3. 종단간 기계학습은 데이터 입력에서 목표한 출력까지의 과정에 사람의 개입 없이 얻는다는 의미입니다.\n",
    "4. 신경망의 이점은 서로 다른 종류의 데이터를 분류나 회귀문제와 같은 일관된 관점에서 문제해결이 가능합니다. \n",
    "5. 신경망은 주어진 데이터들을 그대로 입력 데이터로 활용해 \"end-to-end\"로 학습할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 1번 기계학습에서는 이미지의 특징을 SIFT, SURF등의 알고리즘을 통해서 사람이 설계했지만, 신경망은 이미지에 포함된 중요한 특징까지 스스로 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련데이터와 시험 데이터에 대하여 올바르지 않은 것을 고르시오.\n",
    "훈련데이터와 시험 데이터\n",
    "1. 기계학습 문제는 데이터를 훈련 데이터와 시험 데이터로 나눠 학습과 시험을 수행하는 것이 일반적입니다.\n",
    "2. 훈련 데이터는 학습에 사용되어 최적의 매개변수를 찾는데 활용됩니다.\n",
    "3. 훈련 데이터로 만들어진 모델의 성능을 훈련 데이터를 통하여 평가합니다.\n",
    "4. 훈련 데이터와 시험 데이터를 나누는 이유는 훈련된 모델이 범용적으로 사용가능한 모델이기를 원하기 때문입니다.\n",
    "5. 시험 데이터를 제대로 맞추지 못하고 한 데이터셋에만 지나치게 최적화된 상태를 오버피팅이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 3번 훈련데이터로 만들어진 모델을 시험 데이터를 통하여 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수에 대하여 올바르지 않은 것을 고르시오.\n",
    "손실함수\n",
    "1. 손실함수란 신경망의 성능을 나타내는 지표로, 신경망은 이 지표를 기준으로 최적의 매개변수 값을 탐색합니다.\n",
    "2. 회귀문제에서는 평균제곱오차을 손실함수로 사용할 수 있고, 분류문제에서는 교차 엔트로피 오차를 사용할 수 있습니다.\n",
    "3. 오차제곱합은 모델이 추정 값과 참 값의 차이를 제곱하여 모두 더한 값입니다.\n",
    "4. 교차 엔트로피의 식은 $E = -\\sum{t_klogy_k}$로, $t_k$는 모델의 출력값을, $y_k$는 정답값을 의미합니다.\n",
    "5. 교차 엔트로피 오차는 모델의 출력값이 커질수록 오차가 감소하다가, 출력값이 1이 되면 오차는 0이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 4번 $E = -\\sum{t_klogy_k}$로, $t_k$는 정답값을, $y_k$는 신경망의 출력값을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미니배치 학습에 대한 내용으로 올바르지 않은 것을 고르시오.\n",
    "미니배치 학습\n",
    "1. 각 데이터에 대한 손실 함수 값을 하나씩 계산하면 시간과 자원의 손실이 발생합니다.\n",
    "2. N개의 훈련데이터의 손실함수를 평균 손실 함수라는 하나의 지표로 통일함으로써 훈련 데이터 개수에 상관없이 언제든 통일된 지표를 얻을 수 있습니다.\n",
    "3. 훈련 데이터로부터 일부만을 골라 한번만 학습을 수행하는 것을 미니배치라고 합니다.\n",
    "4. 예를 들어, 600장의 훈련 데이터 중에서 반복적으로 100장씩 6번을 무작위로 뽑아 그 100장만 사용하여 학습하는 방법을 미니배치 학습이라고 합니다.\n",
    "5. 미니배치는 무작위로 뽑은 일부 훈련 데이터의 손실함수가 전체 데이터의 손실 함수를 대표한다는 관점에서 만들어졌습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 3번 미니배치로 선정되는 데이터들은 훈련 데이터셋에서 무작위로 선택된 데이터들 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수를 이용해 매개변수를 찾는 이유로 올바르지 않은 것을 고르시오.\n",
    "손실 함수를 설정해야하는 이유\n",
    "1. 정확도를 기준으로 삼을 경우 미분값이 대부분의 장소에서 0이 되기에 매개변수를 갱신할 수 없기 때문입니다.\n",
    "2. 매개변수를 조정시 정확도는 불연속적인 값으로 변화합니다.\n",
    "3. 정확도는 매개변수의 변화에 크게 반응을 보이고, 손실 함수는 불연속적으로 변화하게 됩니다.\n",
    "4. 계단 함수를 활성화 함수로 사용하지 않는 이유는 계단 함수의 미분은 대부분 0이기에 매개변수가 주는 작은 변화를 없애버립니다.\n",
    "5. 시그모이드 함수의 미분은 연속적으로 변하기에, 시그모이드 함수를 쓰면 기울기가 0이 되지 않아 신경망이 올바르게 학습할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 3번 정확도는 매개변수의 변화에 크게 반응하지 않으며 손실함수는 연속적으로 변화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망에서 수치미분이 가지는 의미로 올바르지 않은 것을 고르시오.\n",
    "수치 미분\n",
    "1. 아주 작은 변화량인 차분을 0으로 수렴시키는 것을 수치 미분이라고 합니다.\n",
    "2. 중심 차분의 식은 $ \\displaystyle{{{df(x)} \\over {dx}}  = {\\lim_{h \\to 0}}{f(x+h) - f(x-h) \\over 2h}}$사용합니다.\n",
    "3. 변수가 2개 이상인 함수에 대한 미분을 편미분이라고 부릅니다.\n",
    "4. 모든 변수의 편미분을 벡터로 정리한 것을 순간 변화량(기울기)라고 합니다.\n",
    "5. 기울기가 0인 지점은 항상 함수의 최솟값을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 5번 위로 볼록한 함수의 경우 기울기가 0인 지점은 최댓값을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법에 대하여 올바르지 않은 것을 고르시오.\n",
    "경사하강법\n",
    "1. 기계학습은 학습단계에서 손실함수가 최솟값을 가지는 최적의 매개변수를 찾는데 활용되는 기술중 하나가 경사하강법입니다.\n",
    "2. 기울기가 가르키는 방향으로 최적화시 항상 손실함수의 최솟값을 얻을 수 있습니다.\n",
    "3. 경사하강법은 현 위치에서 기울어진 방향으로 일정거리 만큼 이동하고 이동한 곳에서도 기울기를 구하는 과정을 반복하여, 손실함수의 값을 줄여나가는 방법입니다.\n",
    "4. 경사하강법은 기계학습과 신경망에서 자주 사용되는 최적화 기법입니다.\n",
    "5. 한번의 학습으로 얼만큼 학습할지, 즉 매개변수를 얼만큼 갱신하느냐를 정하는 것이 학습률입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : 2번 기울기가 가르키는 방향으로 최적화를 하여도 그쪽이 정말로 최솟값의 방향인지는 보장할 수 없습니다. 왜냐하면 볼록함수의 기울기가 0인 지점이 최솟값이라고 생각하지만 최댓값일 수도 있고, 볼록함수의 기울기가 평평한 경우에는 학습이 진행되지 않는 정체기에 빠질 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률과 같이 사람이 직접 설정해야 하는 매개변수를 하이퍼파라미터라고 부릅니다.\n",
    "하이퍼파라미터 정의  \n",
    "Yes / No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망에서 가중치 매개변수의 변화량에 따른 손실함수의 변화량을 수식으로 표현하면 $\\partial{L} \\over \\partial{W}$ 입니다.\n",
    "신경망에서의 기울기  \n",
    "Yes / No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 : Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음의 알고리즘들을 구현하는데 비어있는 부분은 채워서 올바른 결과를 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from dataset.mnist import load_mnist\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "y_hat = np.array([0.1, 0.05, 0.6, 0.0, 0.5, 0.1])\n",
    "y = np.array([0, 0, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균제곱오차\n",
    "```np.sum()```함수를 사용하여 평균제곱오차을 만드시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21625000000000003"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_square_error(y_hat, y):\n",
    "    return np.mean((y_hat - y)**2) # 빈칸\n",
    "sum_square_error(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차\n",
    "교차 엔트로피를 구현하는데 발생하는 ```RuntimeWarning:```를 해결하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-877ed33e6ba5>:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(t * np.log(y))\n",
      "<ipython-input-12-877ed33e6ba5>:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(t * np.log(y))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y_hat, y):\n",
    "    return -np.sum(t * np.log(y))\n",
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 데이터\n",
    "train 데이터를 ```np.random.choice```함수를 이용하여 10개의 배치단위가 나오도록 만드록 만드시오. x_batch의 shape는 (10,784) 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 빈칸\n",
    "x_batch = x_train[batch_mask]\n",
    "y_batch = y_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_batch\n",
    "# 해당 y는 batch_cross_entropy 함수를 작동시키기 위해서 임시로 만든 변수입니다.\n",
    "tmp = y_hat.copy() \n",
    "np.random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치용 교차 엔트로피 오차 \n",
    "```boolean mask```를 활용한 배치용 교차 엔트로피 오차를 구현하시오.  \n",
    "```boolean mask```는 배열의 값들을 불러오는데 값이 0이나 False이면 불러오지 않고 0이아닌 실수이거나 True이면 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.82666925670826"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_cross_entropy(y_hat, y):\n",
    "    if y_hat.ndim == 1:\n",
    "        y_hat = y_hat.reshape(1, y_hat.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y_hat.shape[0]\n",
    "    return -np.sum(y * np.log(y_hat + 1e-7)) / batch_size # 빈칸\n",
    "\n",
    "batch_cross_entropy(y_hat, tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중심 차분\n",
    "중심차분의 식은 $\\lim_{h->0}\\frac{f(x+h) - f(x-h)}{2*h}$ 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h) # 빈칸\n",
    "\n",
    "def example_function(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "x = 5\n",
    "numerical_diff(example_function, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기\n",
    "기울기는 모든 변수의 편미분을 벡터로 정리한 것을 말합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) # 빈칸\n",
    "    return grad\n",
    "\n",
    "def example_multi_function(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "numerical_gradient(example_multi_function, np.array([3.0,4.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강법\n",
    "경사하강법의 식은 $w_{next} = w_i - \\frac{\\partial Loss}{\\partial w_i} * a$ 입니다. \n",
    "$w_i$는 i번째 가중치이고, $a$는 학습률을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0005, -0.0005])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(f, x, a=0.1, step_num=100):\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= a * grad # 빈칸\n",
    "    return x\n",
    "x = np.array([-3.0, 4.0])\n",
    "gradient_descent(example_multi_function, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
